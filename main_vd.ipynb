{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "# from scipy import linalg\n",
    "# from scipy import ndimage\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 924 images belonging to 8 classes.\n",
      "Found 233 images belonging to 8 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BA- cellulitis': 0,\n",
       " 'BA-impetigo': 1,\n",
       " 'FU-athlete-foot': 2,\n",
       " 'FU-nail-fungus': 3,\n",
       " 'FU-ringworm': 4,\n",
       " 'PA-cutaneous-larva-migrans': 5,\n",
       " 'VI-chickenpox': 6,\n",
       " 'VI-shingles': 7}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEKLARASI PATH DATA TRAIN DAN TEST\n",
    "TrainingImagePath=  r\"..\\visila\\skin-disease-datasaet\\train_set\"\n",
    "TestImagePath = r\"..\\visila\\skin-disease-datasaet\\test_set\"\n",
    "\n",
    "# IMAGE DATA GENERATOR -> UNTUK AUGMENTASI GAMBAR PADA DATASHEET TRAINING\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# MEMBUAT OBJEK UNTUK RESCALLING PADA DATASHEET TRAINING\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# MEMBUAT DATASHEET TRAINING DARI DIREKTORI, GAMBAR AKAN DIRUBAH SESUAI DENGAN KONFIGURASI YANG DITENTUKAN\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')  # KARENA DATA INI BERKATEGORI BUKAN BINARY\n",
    "\n",
    "# MEMBUAT DATASHEET TESTING DARI DIREKTORI, GAMBAR AKAN DIRUBAH SESUAI DENGAN KONFIGURASI YANG DITENTUKAN\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        TestImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# MENDAPATKAN INDEKS CLASS YANG SUDAH DITEMUKAN DALAM DATASHEET PENGUJIAN\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of Face and its ID {0: 'BA- cellulitis', 1: 'BA-impetigo', 2: 'FU-athlete-foot', 3: 'FU-nail-fungus', 4: 'FU-ringworm', 5: 'PA-cutaneous-larva-migrans', 6: 'VI-chickenpox', 7: 'VI-shingles'}\n"
     ]
    }
   ],
   "source": [
    "# MENGAMBIL INDEKS DARI DATASHEET CLASS SEBELUMNYA\n",
    "TrainClasses = training_set.class_indices\n",
    "\n",
    "# MEMBUAT PEMETAAN YANG HASILNYA DALAM BENTUK DICTIONARY\n",
    "ResultMap = {}\n",
    "for faceValue, faceName in zip(TrainClasses.values(), TrainClasses.keys()):\n",
    "    ResultMap[faceValue] = faceName\n",
    "\n",
    "with open(\"ResultsMap.pkl\", 'wb') as fileWriteStream:\n",
    "    pickle.dump(ResultMap, fileWriteStream)\n",
    "\n",
    "# MENAMPILKAN PEMETAAN ID CLASS DAN NAMA CLASS\n",
    "print(\"Mapping of Face and its ID\", ResultMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Number of output neurons:  8\n",
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 60, 60, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 30, 30, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10816)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                692288    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 746504 (2.85 MB)\n",
      "Trainable params: 746504 (2.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OutputNeurons = len(ResultMap)\n",
    "print('\\n The Number of output neurons: ', OutputNeurons)\n",
    "\n",
    "# MEMBUAT MODEL\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "\n",
    "# MENDEFINISIKAN FUNSGI UNTUK MENJADI MODEL\n",
    "def create_model():\n",
    "    # MODEL SEKUENSIAL\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64, 64, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(OutputNeurons, activation='softmax')\n",
    "    ])\n",
    "    # model = tf.keras.models.Sequential([\n",
    "    #     tf.keras.layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64, 64, 3), activation='relu'),\n",
    "    #     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    #     tf.keras.layers.Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'),\n",
    "    #     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    #     tf.keras.layers.Flatten(),\n",
    "    #     tf.keras.layers.Dense(64, activation='relu'),\n",
    "    #     tf.keras.layers.Dense(OutputNeurons, activation='softmax')\n",
    "    # ])\n",
    "\n",
    "    # MENGKOMPILASI PROGRAM\n",
    "    model.compile(optimizer='adam',  # MENGGUNAKAN ADAM KARENA DATASHEET BERKATEGORI DAN YANG MENDUKUNG ADALAH ADAM\n",
    "                  loss='categorical_crossentropy',  # DATA BERKATEGORI BUKAN BINARY\n",
    "                  metrics=['accuracy'])  # YANG INGIN DILIHAT NILAI AKURASINYA\n",
    "\n",
    "    # MENAMPILKAN RINGKASAN MODEL\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# PANGGIL FUNGSI MODEL\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "29/29 [==============================] - 4s 95ms/step - loss: 2.0337 - accuracy: 0.1905 - val_loss: 1.8827 - val_accuracy: 0.3004\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 2s 84ms/step - loss: 1.8190 - accuracy: 0.3149 - val_loss: 1.8521 - val_accuracy: 0.2704\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 1.6199 - accuracy: 0.4069 - val_loss: 1.6645 - val_accuracy: 0.3991\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 2s 81ms/step - loss: 1.4915 - accuracy: 0.4600 - val_loss: 1.5514 - val_accuracy: 0.4721\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 1.3281 - accuracy: 0.5368 - val_loss: 1.4925 - val_accuracy: 0.4506\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 1.2818 - accuracy: 0.5390 - val_loss: 1.4962 - val_accuracy: 0.4807\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 1.2160 - accuracy: 0.5628 - val_loss: 1.3299 - val_accuracy: 0.5021\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 1.1005 - accuracy: 0.6201 - val_loss: 1.2238 - val_accuracy: 0.5579\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 1.0218 - accuracy: 0.6515 - val_loss: 1.2371 - val_accuracy: 0.5966\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.9862 - accuracy: 0.6558 - val_loss: 1.1969 - val_accuracy: 0.5837\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.8779 - accuracy: 0.6916 - val_loss: 1.0607 - val_accuracy: 0.6524\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 2s 82ms/step - loss: 1.0585 - accuracy: 0.6299 - val_loss: 1.2064 - val_accuracy: 0.6266\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 2s 82ms/step - loss: 0.7736 - accuracy: 0.7348 - val_loss: 0.9932 - val_accuracy: 0.6781\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 0.7043 - accuracy: 0.7695 - val_loss: 0.9863 - val_accuracy: 0.6910\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 2s 81ms/step - loss: 0.7045 - accuracy: 0.7522 - val_loss: 0.9269 - val_accuracy: 0.6867\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 2s 80ms/step - loss: 0.6748 - accuracy: 0.7587 - val_loss: 0.9638 - val_accuracy: 0.6910\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 2s 80ms/step - loss: 0.6095 - accuracy: 0.7900 - val_loss: 0.8650 - val_accuracy: 0.7296\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 2s 83ms/step - loss: 0.5758 - accuracy: 0.8128 - val_loss: 1.0579 - val_accuracy: 0.6953\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 2s 81ms/step - loss: 0.5638 - accuracy: 0.8182 - val_loss: 0.8947 - val_accuracy: 0.7039\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 0.5163 - accuracy: 0.8236 - val_loss: 0.8580 - val_accuracy: 0.7597\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 3s 90ms/step - loss: 0.4955 - accuracy: 0.8312 - val_loss: 0.7893 - val_accuracy: 0.7468\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 3s 86ms/step - loss: 0.4551 - accuracy: 0.8517 - val_loss: 0.8066 - val_accuracy: 0.7554\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 2s 81ms/step - loss: 0.4222 - accuracy: 0.8539 - val_loss: 0.8571 - val_accuracy: 0.7425\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 0.4037 - accuracy: 0.8561 - val_loss: 0.7673 - val_accuracy: 0.7811\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 2s 80ms/step - loss: 0.3899 - accuracy: 0.8690 - val_loss: 0.8995 - val_accuracy: 0.7296\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.3557 - accuracy: 0.8799 - val_loss: 0.8267 - val_accuracy: 0.7768\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.3090 - accuracy: 0.8994 - val_loss: 1.0898 - val_accuracy: 0.7082\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.4014 - accuracy: 0.8680 - val_loss: 0.7818 - val_accuracy: 0.7725\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.2835 - accuracy: 0.9069 - val_loss: 1.0721 - val_accuracy: 0.7339\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 2s 80ms/step - loss: 0.2818 - accuracy: 0.9102 - val_loss: 0.8657 - val_accuracy: 0.7639\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.3169 - accuracy: 0.8918 - val_loss: 0.8387 - val_accuracy: 0.7897\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.2529 - accuracy: 0.9253 - val_loss: 0.8798 - val_accuracy: 0.7768\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 2s 81ms/step - loss: 0.2278 - accuracy: 0.9177 - val_loss: 0.8104 - val_accuracy: 0.8069\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 3s 87ms/step - loss: 0.2086 - accuracy: 0.9340 - val_loss: 0.9090 - val_accuracy: 0.7768\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.2412 - accuracy: 0.9188 - val_loss: 0.9020 - val_accuracy: 0.7725\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 0.2520 - accuracy: 0.9242 - val_loss: 0.7957 - val_accuracy: 0.8026\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.1702 - accuracy: 0.9437 - val_loss: 0.8848 - val_accuracy: 0.8069\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.1510 - accuracy: 0.9535 - val_loss: 0.8625 - val_accuracy: 0.8155\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.1567 - accuracy: 0.9545 - val_loss: 0.8483 - val_accuracy: 0.8155\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.1873 - accuracy: 0.9491 - val_loss: 1.0712 - val_accuracy: 0.7768\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.2419 - accuracy: 0.9210 - val_loss: 0.9032 - val_accuracy: 0.7811\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.1454 - accuracy: 0.9502 - val_loss: 0.9100 - val_accuracy: 0.8155\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.1526 - accuracy: 0.9578 - val_loss: 1.0169 - val_accuracy: 0.7983\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.1515 - accuracy: 0.9481 - val_loss: 0.8925 - val_accuracy: 0.7983\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.1668 - accuracy: 0.9437 - val_loss: 0.8579 - val_accuracy: 0.7897\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.1328 - accuracy: 0.9621 - val_loss: 0.9793 - val_accuracy: 0.8026\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.1375 - accuracy: 0.9556 - val_loss: 0.9053 - val_accuracy: 0.8197\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.1297 - accuracy: 0.9589 - val_loss: 0.9379 - val_accuracy: 0.8155\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 3s 88ms/step - loss: 0.1297 - accuracy: 0.9545 - val_loss: 0.9541 - val_accuracy: 0.8112\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 2s 84ms/step - loss: 0.1582 - accuracy: 0.9481 - val_loss: 1.1305 - val_accuracy: 0.7768\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_set,\n",
    "                    epochs=50,\n",
    "                    validation_data=test_set\n",
    "                    # validation_steps=10\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image Shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load the ResultMap from the pickle file\n",
    "with open(\"ResultsMap.pkl\", 'rb') as fileReadStream:\n",
    "    ResultMap = pickle.load(fileReadStream)\n",
    "\n",
    "\n",
    "image_path = \"../visila/skin-disease-datasaet/train_set/FU-ringworm/0_FU-ringworm (38).jpg\"\n",
    "\n",
    "frame = cv2.imread(image_path)\n",
    "\n",
    "print(\"Original Image Shape:\", frame.shape)\n",
    "\n",
    "\n",
    "# Resize the image to match the input size expected by your model\n",
    "resized_frame = cv2.resize(frame, (64, 64))\n",
    "\n",
    "# Normalize the image\n",
    "img_array = np.expand_dims(resized_frame, axis=0) / 255.0\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class = ResultMap[np.argmax(predictions)]\n",
    "\n",
    "# Display the prediction on the image\n",
    "cv2.putText(frame, f'Prediction: {predicted_class}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with the prediction\n",
    "cv2.imshow('Image Prediction', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m resized_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n\u001b[0;32m      9\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(resized_frame, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m ResultMap[np\u001b[38;5;241m.\u001b[39margmax(predictions)]\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:2620\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2611\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2612\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2617\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2618\u001b[0m         )\n\u001b[1;32m-> 2620\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2624\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2633\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1291\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:353\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 353\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2325\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[0;32m   2322\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2323\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2324\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flat_map_op\n\u001b[1;32m-> 2325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflat_map_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:24\u001b[0m, in \u001b[0;36m_flat_map\u001b[1;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flat_map\u001b[39m(input_dataset, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:42\u001b[0m, in \u001b[0;36m_FlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure\u001b[38;5;241m.\u001b[39m_element_spec\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m---> 42\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mflat_map_dataset(\n\u001b[0;32m     43\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m     45\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:2369\u001b[0m, in \u001b[0;36mflat_map_dataset\u001b[1;34m(input_dataset, other_arguments, f, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   2367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   2368\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2369\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2370\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFlatMapDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_arguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2371\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2372\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   2374\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"ResultsMap.pkl\", 'rb') as fileReadStream:\n",
    "    ResultMap = pickle.load(fileReadStream)\n",
    "\n",
    "cap = cv2.VideoCapture(0)  \n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    resized_frame = cv2.resize(frame, (64, 64))\n",
    "    img_array = np.expand_dims(resized_frame, axis=0) / 255.0\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = ResultMap[np.argmax(predictions)]\n",
    "    cv2.putText(frame, f'Prediction: {predicted_class}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('Webcam Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
